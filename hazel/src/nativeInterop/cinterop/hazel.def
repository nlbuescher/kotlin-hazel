package = hazel.cinterop
compilerOpts = -Isrc/nativeInterop/include
---
#include <stddef.h> // for size_t and uint64_t

static inline size_t sizeOf(void* a)
{
#if defined(_WIN32)
	return _msize(a);
#elif defined(__APPLE__)
	return malloc_size(a);
#else
	return malloc_usable_size(a);
#endif
}


#include <smmintrin.h>
static inline __m128 vec4_add(__m128 a, __m128 b){return _mm_add_ps(a, b);}
static inline __m128 vec4_sub(__m128 a, __m128 b){return _mm_sub_ps(a, b);}
static inline __m128 vec4_mul(__m128 a, __m128 b){return _mm_mul_ps(a, b);}
static inline __m128 vec4_div(__m128 a, __m128 b){return _mm_div_ps(a, b);}

static inline __m128 vec4_round(__m128 x)
{
#if defined(__SSE4_1__)
	return _mm_round_ps(x, _MM_FROUND_TO_NEAREST_INT);
#else
	__m128 const sgn0 = _mm_castsi128_ps(_mm_set1_epi32((int)0x80000000));
	__m128 const and0 = _mm_and_ps(sgn0, x);
	__m128 const or0  = _mm_or_ps(and0, _mm_set_ps1(8388608.0f));
	__m128 const add0 = vec4_add(x, or0);
	__m128 const sub0 = vec4_sub(add0, or0);
	return sub0;
#endif
}

static inline __m128 vec4_floor(__m128 x)
{
#if defined(__SSE4_1__)
	return _mm_floor_ps(x);
#else
	__m128 const rnd0 = vec4_round(x);
	__m128 const cmp0 = _mm_cmplt_ps(x, rnd0);
	__m128 const and0 = _mm_and_ps(cmp0, _mm_set1_ps(1.0f));
	__m128 const sub0 = vec4_sub(rnd0, and0);
	return sub0;
#endif
}

static inline __m128 vec4_mod(__m128 a, __m128 b)
{
	__m128 const div0 = vec4_div(a, b);
    __m128 const flr0 = vec4_floor(div0);
    __m128 const mul0 = vec4_mul(b, flr0);
    __m128 const sub0 = vec4_sub(a, mul0);
    return sub0;
}


// obsolete in master (posix platform lib there defines _DARWIN_C_SOURCE, which enables this function)
#if defined(__APPLE__)
#include <pthread.h>
static inline int pthread_threadid(pthread_t thread, uint64_t* id)
{
	return pthread_threadid_np(thread, id);
}
#endif

#define STB_IMAGE_IMPLEMENTATION
#define STBI_NO_FAILURE_STRINGS
#include <stb_image.h>
